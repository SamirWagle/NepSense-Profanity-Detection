{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3898,"status":"ok","timestamp":1718956292780,"user":{"displayName":"Eemayas Sayamee","userId":"01344633150457036226"},"user_tz":-345},"id":"zjNAId76xJ5P","outputId":"be48c1db-fc8c-49be-a020-d50446c46993"},"outputs":[],"source":["colab=1\n","if colab:\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","  %cd /content/drive/MyDrive/Projects/NepSense/Prashant/Model Training\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YHMIiN95pAZG"},"outputs":[],"source":["# !pip install pandas==2.2.2\n","# !pip install numpy==1.26.4\n","# !pip install nltk=3.8.1\n","# !pip install pycontractions\n","# !pip install scikit-learn\n","# !pip install tqdm\n","# !pip install tensorflow=2.16.1\n","# !pip install numpy\n","# !pip install seaborn\n","# !pip install matplotlib\n","# !pip install langdetect\n","# !pip install keras==3.3.3"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8664,"status":"ok","timestamp":1718509972984,"user":{"displayName":"Eemayas Sayamee","userId":"01344633150457036226"},"user_tz":-345},"id":"OD9Ic8FrL_I_","outputId":"cf257b0c-533b-4a01-8fb9-f41f659b445d"},"outputs":[],"source":["import tensorflow as tf\n","\n","# Check if GPU is available\n","print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n","\n","# Explicitly allow memory growth\n","gpus = tf.config.experimental.list_physical_devices('GPU')\n","if gpus:\n","    try:\n","        for gpu in gpus:\n","            tf.config.experimental.set_memory_growth(gpu, True)\n","        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n","        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n","    except RuntimeError as e:\n","        print(e)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6JREBrpwpZ0B"},"outputs":[],"source":["import nltk\n","from nltk.tokenize import word_tokenize,sent_tokenize\n","from nltk.stem import WordNetLemmatizer,PorterStemmer\n","import pandas as pd\n","import numpy as np\n","import seaborn as sn\n","from tqdm import tqdm\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import classification_report"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qhj4fnGcHusV"},"outputs":[],"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense,Flatten, GlobalMaxPooling1D,GlobalAveragePooling1D, Embedding, Conv1D\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.utils import to_categorical\n","from keras.callbacks import EarlyStopping\n","from tensorflow.keras.preprocessing.text import one_hot, Tokenizer\n","from keras.layers import Activation, Dropout, Dense\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":710,"status":"ok","timestamp":1718899246219,"user":{"displayName":"Eemayas Sayamee","userId":"01344633150457036226"},"user_tz":-345},"id":"u3x78iGBrAPZ","outputId":"0091a680-9d0f-4d07-d560-c25bef5b8704"},"outputs":[],"source":["nltk.download(\"stopwords\")\n","# wordnet is foro lemmanation and stemmation\n","nltk.download(\"wordnet\")\n","# punkt is for sent_tokenizer\n","nltk.download(\"punkt\")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1544,"status":"ok","timestamp":1718956445961,"user":{"displayName":"Eemayas Sayamee","userId":"01344633150457036226"},"user_tz":-345},"id":"RvSO0Qsn64NO"},"outputs":[],"source":["import pandas as pd\n","dataset=\"./Model Training Datas/embeddings.csv\"\n","df = pd.read_csv(dataset)\n","# Assuming df is your DataFrame\n","# Select rows with label 0 and 2\n","df = df[df['Label'].isin([0, 1])]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":480},"executionInfo":{"elapsed":1032,"status":"ok","timestamp":1718899269781,"user":{"displayName":"Eemayas Sayamee","userId":"01344633150457036226"},"user_tz":-345},"id":"Qwmqb9KXOV5K","outputId":"c7eb7ba3-1421-4957-eeb2-a8775690ebde"},"outputs":[],"source":["import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# Assuming 'df' is your DataFrame with the 'SentimentScore' column\n","sns.set(style=\"darkgrid\")\n","\n","# Create a countplot\n","ax = sns.countplot(x='Label', data=df)\n","\n","# Add count annotations on top of the bars\n","for p in ax.patches:\n","    ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()),\n","                ha='center', va='center', xytext=(0, 10), textcoords='offset points')\n","\n","# Set labels and title\n","ax.set_xlabel(\"Sentiment Score\")\n","ax.set_ylabel(\"Count\")\n","ax.set_title(\"Sentiment Score Count\")\n","\n","# Show the plot\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":788},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1718899269782,"user":{"displayName":"Eemayas Sayamee","userId":"01344633150457036226"},"user_tz":-345},"id":"d5WxLI-OtMKA","outputId":"efc1f5d1-d2a4-4ab8-c930-5b36274db8dd"},"outputs":[],"source":["df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UlSvVhzMazdc"},"outputs":[],"source":["X=df[\"preprocessing_text\"]\n","Y=df[\"Label\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5DKQEnfqK9Qi"},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20,stratify=Y, random_state=42)\n","# The train set will be used to train our deep learning models\n","# while test set will be used to evaluate how well our model performs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1718899269783,"user":{"displayName":"Eemayas Sayamee","userId":"01344633150457036226"},"user_tz":-345},"id":"2tcRPkrUxhhr","outputId":"8ba876ab-d908-4eb8-a045-daa14ed98ae3"},"outputs":[],"source":["unique_labels = set(y_train)\n","print(unique_labels)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1718899269783,"user":{"displayName":"Eemayas Sayamee","userId":"01344633150457036226"},"user_tz":-345},"id":"ul-KoMGIbF22","outputId":"546a973c-54eb-48d3-84d2-e568da6b3742"},"outputs":[],"source":["# print(y_train.count())\n","# print(y_test.count())\n","# X_train.head()\n","# Create a countplot\n","# Count occurrences of each value\n","value_counts = np.bincount(y_train)\n","\n","# Print the counts\n","print(\"Counts of 1:\", value_counts[0])\n","print(\"Counts of 2:\", value_counts[1])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1718899269783,"user":{"displayName":"Eemayas Sayamee","userId":"01344633150457036226"},"user_tz":-345},"id":"aBXTdnmEDL7Q","outputId":"d7ee3fd7-b51e-4a81-dd37-fd7f11615eab"},"outputs":[],"source":["type(X_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IP5OOir8J1-4"},"outputs":[],"source":["\n","# Embedding layer expects the words to be in numeric form\n","# Using Tokenizer function from keras.preprocessing.text library\n","# Method fit_on_text trains the tokenizer\n","# Method texts_to_sequences converts sentences to their numeric form\n","#Must run above shell\n","word_tokenizer =  Tokenizer(num_words=90000,\n","                      lower=True,\n","                      split=' ',\n","                      char_level=False,\n","                      oov_token='<UNK>',\n","                      document_count=0)\n","\n","word_tokenizer.fit_on_texts(X_train)\n","\n","wordindex=word_tokenizer.word_index\n","X_train = word_tokenizer.texts_to_sequences(X_train)\n","X_test = word_tokenizer.texts_to_sequences(X_test)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1718899286571,"user":{"displayName":"Eemayas Sayamee","userId":"01344633150457036226"},"user_tz":-345},"id":"qRJbd6CwLPj8","outputId":"7c83ef59-14b9-4555-bf35-c601fb066fde"},"outputs":[],"source":["# Adding 1 to store dimensions for words for which no pretrained word embeddings exist\n","\n","vocab_length = len(wordindex) + 1\n","\n","vocab_length"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nxCQ3XeWMKTv"},"outputs":[],"source":["# Padding all reviews to fixed length 100\n","max_len=500\n","X_train = pad_sequences(X_train, padding='post',maxlen=max_len)\n","X_test = pad_sequences(X_test, padding='post',maxlen=max_len)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1718899288842,"user":{"displayName":"Eemayas Sayamee","userId":"01344633150457036226"},"user_tz":-345},"id":"y-112irhZJ4W","outputId":"fbc51bdb-7e47-4512-bbd2-9c5c49ddcba9"},"outputs":[],"source":["#print(test_padding[0])\n","#train_padding[0]\n","X_train.shape\n","y_train.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1718899290054,"user":{"displayName":"Eemayas Sayamee","userId":"01344633150457036226"},"user_tz":-345},"id":"PHM2wTGoWxcY","outputId":"6f491e74-2be9-4af6-aeaa-445a9517379e"},"outputs":[],"source":["from sklearn.preprocessing import OneHotEncoder\n","import numpy as np\n","\n","# Create an instance of OneHotEncoder\n","encoder = OneHotEncoder()\n","\n","# Convert pandas Series to NumPy array\n","y_train_array = np.array(y_train).reshape(-1, 1)\n","y_test_array = np.array(y_test).reshape(-1, 1)\n","\n","# Fit and transform on training data\n","y_train = encoder.fit_transform(y_train_array)\n","\n","# Transform only on test data\n","y_test = encoder.transform(y_test_array)\n","\n","# Check the shape of the transformed arrays\n","print(\"Shape of y_train_encoded:\", y_train.shape)\n","print(\"Shape of y_test_encoded:\", y_test.shape)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2290,"status":"ok","timestamp":1718899294117,"user":{"displayName":"Eemayas Sayamee","userId":"01344633150457036226"},"user_tz":-345},"id":"fZ4P0-mAgcuK","outputId":"687880b3-a3c6-42f8-f076-f7e16700e58b"},"outputs":[],"source":["# # Neural Network architecture\n","from keras.models import Sequential\n","from keras.layers import Embedding, Dropout, Bidirectional, LSTM, Dense, Input\n","from keras.constraints import max_norm\n","from keras.regularizers import l2\n","from tensorflow.keras.utils import plot_model\n","from keras.optimizers import Adam\n","\n","# Define the regularizer\n","regularise = l2(0.0001)\n","\n","# Create the Sequential model\n","binomial_lstm_offensive_model = Sequential()\n","binomial_lstm_offensive_model.add(Input(shape=(X_train.shape[1],)))\n","embedding_layer = Embedding(vocab_length, 256)\n","binomial_lstm_offensive_model.add(embedding_layer)\n","binomial_lstm_offensive_model.add(Dropout(0.7))\n","binomial_lstm_offensive_model.add(Bidirectional(LSTM(128, return_sequences=True)))\n","binomial_lstm_offensive_model.add(Bidirectional(LSTM(64, kernel_constraint=max_norm(3))))\n","binomial_lstm_offensive_model.add(Dense(64, activation='relu', kernel_regularizer=regularise))\n","binomial_lstm_offensive_model.add(Dropout(0.7))\n","binomial_lstm_offensive_model.add(Dense(2, activation='sigmoid'))\n","plot_model(binomial_lstm_offensive_model, to_file='model_diagram.png', show_shapes=True, show_layer_names=True)\n","optimizer = Adam(learning_rate=0.00006)\n","binomial_lstm_offensive_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Print model summary\n","print(binomial_lstm_offensive_model.summary())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":865},"executionInfo":{"elapsed":945,"status":"ok","timestamp":1718899298577,"user":{"displayName":"Eemayas Sayamee","userId":"01344633150457036226"},"user_tz":-345},"id":"3xBvGdFHDBYQ","outputId":"2060831c-424b-4071-cbc7-c00798ea74fd"},"outputs":[],"source":["plot_model(binomial_lstm_offensive_model, to_file='model_diagram.png', show_shapes=True, show_layer_names=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":484,"status":"ok","timestamp":1718900304250,"user":{"displayName":"Eemayas Sayamee","userId":"01344633150457036226"},"user_tz":-345},"id":"o0W2xiv4cSAt","outputId":"5de8c257-780b-40da-f476-205533d401bc"},"outputs":[],"source":["X_train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Sl1igUJ1yfT"},"outputs":[],"source":["y_train=np.array(y_train.toarray())\n","X_train=np.array(X_train)\n","y_test=np.array(y_test.toarray())\n","X_test=np.array(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rpjlfpuS64NQ"},"outputs":[],"source":["from keras.callbacks import LearningRateScheduler\n","\n","def scheduler(epoch, lr):\n","    if epoch < 4:\n","        return lr\n","    else:\n","        return lr * 0.1\n","\n","lr_scheduler = LearningRateScheduler(scheduler)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":70406,"status":"ok","timestamp":1718510241390,"user":{"displayName":"Eemayas Sayamee","userId":"01344633150457036226"},"user_tz":-345},"id":"OtFrvJA7kGXW","outputId":"dbf4f1d5-cb4a-46a1-dbc8-b2154a8809da"},"outputs":[],"source":["from keras.models import save_model\n","from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n","import json\n","# Train the model\n","epochs =30\n","batch_size = 128\n","# modeltrain=lstm_model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,validation_split=0.2)\n","# Callbacks\n","early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=False)\n","# lr_scheduler = LearningRateScheduler(scheduler)\n","lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0000001)\n","\n","regularizemodel=binomial_lstm_offensive_model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,validation_split=0.2,callbacks=[early_stopping,lr_scheduler])\n","\n","\n","# # Assuming you have a Keras model named 'model'\n","# lstm_model.save('/content/drive/My Drive/CommentSenseData/LSTMsentimentmodel.h5')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":943},"executionInfo":{"elapsed":1227,"status":"ok","timestamp":1718510242602,"user":{"displayName":"Eemayas Sayamee","userId":"01344633150457036226"},"user_tz":-345},"id":"zOvzM1aBozHO","outputId":"9d27c854-ac41-4044-dc8d-7d4b36ffd1e1"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","# Function to plot training and validation accuracy\n","def plot_accuracy(history):\n","    plt.plot(history.history['accuracy'])\n","    plt.plot(history.history['val_accuracy'])\n","    plt.title('Offensive Model Accuracy')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Accuracy')\n","    plt.legend(['Train', 'Validation'], loc='upper left')\n","    plt.show()\n","\n","# Function to plot training and validation loss\n","def plot_loss(history):\n","    plt.plot(history.history['loss'])\n","    plt.plot(history.history['val_loss'])\n","    plt.title('Offensive Model Loss')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend(['Train', 'Validation'], loc='upper left')\n","    plt.show()\n","\n","  # Plot training and validation accuracy\n","plot_accuracy(regularizemodel)\n","\n","# Plot training and validation loss\n","plot_loss(regularizemodel)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1718510242602,"user":{"displayName":"Eemayas Sayamee","userId":"01344633150457036226"},"user_tz":-345},"id":"iOLdzGXL6Vky","outputId":"75b5bba7-ae01-409f-d610-55381a340f78"},"outputs":[],"source":["epochs = 5\n","batch_size = 128\n","score = binomial_lstm_offensive_model.evaluate(X_test,y_test,batch_size=batch_size)\n","print(\"Testing Accuracy(%): \", score[1]*100)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1718510242602,"user":{"displayName":"Eemayas Sayamee","userId":"01344633150457036226"},"user_tz":-345},"id":"wOublOStrMGc","outputId":"bd3ff916-9ab1-400b-b2d7-b2337e09bbaf"},"outputs":[],"source":["y_predictions = binomial_lstm_offensive_model.predict(X_test)\n","y_pred_labels = np.array([ np.argmax(i) for i in y_predictions])\n","y_test_labels = np.array([ np.argmax(i) for i in y_test])\n","\n","\n","# print(y_predictions)\n","# print(y_pred_labels)\n","# print(y_test_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":396},"executionInfo":{"elapsed":1064,"status":"ok","timestamp":1718510243664,"user":{"displayName":"Eemayas Sayamee","userId":"01344633150457036226"},"user_tz":-345},"id":"97HW6Ut7s_A2","outputId":"5ac6d2aa-81d5-46ed-ee7e-df8909cc860b"},"outputs":[],"source":["confusion = confusion_matrix(y_test_labels, y_pred_labels)\n","labels=['None','Offensive']\n","plt.figure(figsize=(4,4))\n","sn.heatmap(confusion,  xticklabels=labels, yticklabels=labels, fmt='d', annot=True, cmap=plt.cm.Blues)\n","plt.xlabel('Predicted')\n","plt.ylabel('Actual')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1718510243665,"user":{"displayName":"Eemayas Sayamee","userId":"01344633150457036226"},"user_tz":-345},"id":"RqHAhSdutBOu","outputId":"00b6eac9-4dd7-4ea2-e8f8-a0feebf6a174"},"outputs":[],"source":["\n","print('\\nClassification Report for Bidirectional LSTM\\n')\n","print(classification_report(y_test_labels, y_pred_labels, target_names=['Class  None',\t 'Class Offensive']))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bTiATMPt4G89"},"outputs":[],"source":["import pickle\n","\n","binomial_lstm_offensive_model_name= 'Binomial_LSTM_Offensive'\n","binomial_lstm_offensive_model_path= f'/content/drive/MyDrive/Projects/NepSense/{binomial_lstm_offensive_model_name}.keras'\n","binomial_lstm_offensive_tokenizer_path= f'/content/drive/MyDrive/Projects/NepSense/{binomial_lstm_offensive_model_name}.pkl'\n","\n","binomial_lstm_offensive_model.save(binomial_lstm_offensive_model_path)\n","# Save the tokenizer\n","with open(binomial_lstm_offensive_tokenizer_path, 'wb') as f:\n","    pickle.dump(word_tokenizer, f)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10883,"status":"ok","timestamp":1718510254538,"user":{"displayName":"Eemayas Sayamee","userId":"01344633150457036226"},"user_tz":-345},"id":"exROTzmd7nzU","outputId":"3a92ce30-7751-408c-bb86-c9fb7340eb6f"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.models import load_model\n","from keras.preprocessing.sequence import pad_sequences\n","import pickle\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras import initializers\n","\n","import pickle\n","from tensorflow.keras.models import load_model\n","\n","# Load the model\n","binomial_lstm_offensive_model = load_model(binomial_lstm_offensive_model_path)\n","\n","# Load the tokenizer\n","with open(binomial_lstm_offensive_tokenizer_path, 'rb') as f:\n","    binomial_lstm_offensive_tokenizer = pickle.load(f)\n","\n","# Function to preprocess and predict the sentiment of user input\n","def predict_sentiment(input_text):\n","    # Preprocess the input text\n","    input_sequence = binomial_lstm_offensive_tokenizer.texts_to_sequences([input_text])\n","    input_padded = pad_sequences(input_sequence, maxlen=500, padding='post')\n","\n","    # Predict the sentiment\n","    prediction = binomial_lstm_offensive_model.predict(input_padded)\n","    predicted_label = prediction.argmax(axis=-1)[0]\n","\n","    # Map the predicted label to the sentiment class\n","    label_map = {0: 'Non-Offensive', 1: 'Offensive'}\n","    result = label_map[predicted_label]\n","\n","    return result\n","\n","# Ask the user for input and display the result\n","user_input = input(\"Enter a sentence to check for offensive: \")\n","sentiment_result = predict_sentiment(user_input)\n","print(f\"The sentence is: {sentiment_result}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DKegPFAJMHx9"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.19"}},"nbformat":4,"nbformat_minor":0}
